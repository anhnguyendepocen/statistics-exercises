---
title: "Data Analysis and Graphics Using R"
author: "Gabriele Sarti, Katja Valiavec, Leticia Negrao Pinto"
date: "March 19, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 4

**For the data frame possum (DAAG package)**

**(a) Use the function str() to get information on each of the columns.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
library(DAAG)
for (col in names(possum))
{
  str(possum[col])
}
```

**(b) Using the function complete.cases(), determine the rows in which one or more values is missing. Print those rows. In which columns do the missing values appear?**

There are two missing values in `age` and a missing value in `footlgth`.

```{r echo=TRUE,  message=FALSE, warning=FALSE}
library(DAAG)
possum[!complete.cases(possum),]
```

## Exercise 6

**Create a data frame called Manitoba.lakes that contains the lake’s elevation (in meters above sea level) and area (in square kilometers) as listed below. Assign the names of the lakes using the row.names() function.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
lakes <- c("Winnipeg", "Winnipegosis", "Manitoba", "SouthernIndian", 
           "Cedar", "Island", "Gods", "Cross", "Playgreen")
elevation <- c(217, 254, 248, 254, 253, 227, 178, 207, 217)
area <- c(24387, 5374, 4624, 2247, 1353, 1223, 1151, 755, 657)

#Create data frame
Manitoba.lakes <- data.frame(elevation, area)

#Assigning names
row.names(Manitoba.lakes) = lakes
Manitoba.lakes
```

**a) Use the following code to plot(log2(area)) versus elevation, adding labeling information (there is an extreme value of area that makes a logarithmic scale pretty much essential).**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
attach(Manitoba.lakes)
plot(log2(area) ~ elevation, pch=16, xlim=c(170,280))
#NB: Doubling the area increases log2(area) by 1.0
text(log2(area) ~ elevation, labels=row.names(Manitoba.lakes), pos=4)
text(log2(area) ~ elevation, labels=area, pos=2)
title("Manitoba's Largest Lakes")
detach(Manitoba.lakes)
```

**b) Repeat the plot and associated labeling, now plotting area versus elevation, but specifying log="y"in order to obtain a logarithmic y-scale.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
attach(Manitoba.lakes)
plot(area ~ elevation, log="y", pch=16, xlim=c(170,280))
#NB: Doubling the area increases log2(area) by 1.0
text(area ~ elevation, labels=row.names(Manitoba.lakes), pos=4)
text(area ~ elevation, labels=area, pos=2)
title("Manitoba's Largest Lakes")
detach(Manitoba.lakes)
```

## Exercise 11

**Run the following code:**
```{r echo=TRUE,  message=FALSE, warning=FALSE}
gender <- factor(c(rep("female", 91), rep("male", 92)))
table(gender)
gender <- factor(gender, levels=c("male", "female"))
table(gender)
gender <- factor(gender, levels=c("Male", "female")) # Note the mistake: "Male" should be "male"
table(gender)
table(gender, exclude=NULL)
rm(gender) # Remove gender
```
**Explain the output from the successive uses of table().**

At first a vector named 'gender' was constructed with two categories: 'male' and 'female'.

   (#1) The first table() returns the number of males and females as defined in the assignement of 'gender'.
   
   (#2) The second table() returns the same as the previous one, but this time the vector was redefined to be the levels of 'male' and 'female' of vector 'gender'.
   
   (#3) The third table() will not return the results for 'male' because of the typo ('Male' instead of 'male') when redefining the vector 'gender'. In this case the vector will have only 'female' and an unnamed level for lowercase 'male', so the table() will return 0 uppercase Male.
   
   (#4) Finally, when we type 'table(gender, exclude=NULL)' it will return the amount correspondent to all levels in gender vector, namely 'Male', 'female', and the level which previously was 'male', but now is unnamed, as discussed previously.

## Exercise 12

**Write a function that calculates the proportion of values in a vector x that exceed some value cutoff.**

**(a) Use the sequence of numbers **$1, 2, \dots , 100$ **to check that this function gives the result that is expected.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
exceed_prop <- function(X, cutoff)
{
  return(length(X[X > cutoff])/length(X))
}
sequence <- c(1:100)
print(paste("Higher than 0:", exceed_prop(sequence, 0)))
print(paste("Higher than 50:", exceed_prop(sequence, 50)))
print(paste("Higher than 70:", exceed_prop(sequence, 70)))
print(paste("Higher than 100:", exceed_prop(sequence, 100)))
```

**(b) Obtain the vector ex01.36 from the Devore6 (or Devore7) package. These data give the times required for individuals to escape from an oil platform during a drill. Use dotplot() to show the distribution of times. Calculate the proportion of escape times that exceed 7 minutes.**

We assume that the times contained in the vector are expressed in seconds.


```{r echo=TRUE,  message=FALSE, warning=FALSE}
library(Devore7)
exceed_prop <- function(X, cutoff)
{
  return(length(X[X > cutoff])/length(X))
}
dotplot(ex01.36$C1)
print(paste("Proportion above 7 minutes:", exceed_prop(ex01.36$C1, 7 * 60)))
```

## Exercise 13

**The following plots four different transformations of the Animals data from the MASS package. What different aspects of the data do these different graphs emphasize? Consider the effect on low values of the variables, as contrasted with the effect on high values.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
par(mfrow=c(2,2)) # 2 by 2 layout on the page
library(MASS) # Animals is in the MASS package
plot(brain  ~ body, data=Animals)
plot(sqrt(brain)  ~ sqrt(body), data=Animals)
plot(I(brain^0.1) ~ I(body^0.1), data=Animals) # I() forces its argument to be treated "as is"
plot(log(brain) ~ log(body), data=Animals)
par(mfrow=c(1,1)) # Restore to 1 figure per page
```

The first graph presents us with the range of values in the data, and we can observe, that there are only few points that are much larger than the rest of the data (skewness towards large values). This results in unclear representation, since the majority of the points lies close to the origin.  Even in the second graph, where we apply square root function and the effect of outliers minimizes, the presentation of the data is not yet satisfactory. Applying the next transformation data becomes more hashed and we can already see clearer correlation between values.

With the final logarithmic representation, we reduce wide range of quantities to a more manageable size and make our data equally spread, which makes a clear representation of correlation between brain and body size.

## Exercise 15

**The data frame socsupport (DAAG) has data from a survey on social and other kinds of support, for a group of university students. It includes Beck Depression Inventory (BDI) scores. The following are two alternative plots of BDI against age:**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
library(DAAG)
par(mfrow=c(1,2))

plot(BDI ~ age, data=socsupport)
plot(BDI ~ unclass(age), data=socsupport)
```

**For examination of cases where the score seems very high, which plot is more useful? Explain.**

In cases where the score seems very high the most useful plot is the first one (`plot(BDI ~ age, data=socsupport)`) because the outliars appear explicitly.

**Why is it necessary to be cautious in making anything of the plots for students in the three oldest age categories (25-30, 31-40, 40+)?**

We need to be cautious because the number of students in these categories is very low to make inferences.

```{r, echo=TRUE,  message=FALSE, warning=FALSE}
library(DAAG)
data = socsupport 
table(data$age)
```

## Exercise 17

**Given a vector x, the following demonstrates alternative ways to create a vector of numbers from 1 through n, where n is the length of the vector:**
```{r echo=TRUE,  message=FALSE, warning=FALSE}
x <- c(8, 54, 534, 1630, 6611)
seq(1, length(x))
seq(along=x)
```
**Now set x <- NULL and repeat each of the calculations seq(1, length(x)) and seq(along=x). Which version of the calculation should be used in order to return a vector of length 0 in the event that the supplied argument is NULL.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
x <- NULL
seq(1, length(x))
seq(along=x)
```

The second version of the calculation, `seq(along=x)`, should be used in case that the supplied argument is NULL, since the first index (1) of the first version will lead to a descending vector from 1 to 0 instead of the expected result of a vector of length 0.

## Exercise 20

**The help page for iris (type help(iris)) gives code that converts the data in iris3 (datasets package) to case-by-variable format, with column names “Sepal.Length”, “Sepal.Width”, “Petal.Length”, “Petal.Width”, and “Species”. Look up the help pages for the functions that are used, and make sure that you understand them. Then add annotation to this code that explains each step in the computation.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
help(iris)
```

iris is a data frame with 150 cases (rows) and 5 variables (columns) named Sepal.Length, Sepal.Width, Petal.Length, Petal.Width, and Species.

iris3 gives the same data arranged as a 3-dimensional array of size 50 by 4 by 3, as represented by S-PLUS. The first dimension gives the case number within the species subsample, the second the measurements with names Sepal L., Sepal W., Petal L., and Petal W., and the third the species.

```{r echo=TRUE,  message=FALSE, warning=FALSE}
# To obtain dimension names of iris3 dataset. Output:
# 1.NULL
# 2. 'Sepal L.' 'Sepal W.' 'Petal L.' 'Petal W.'
# 3. 'Setosa' 'Versicolor' 'Virginica'
dni3 <- dimnames(iris3) 


# Creates a new dataframe. Function 'aperm' is used to transpose an
# array by permuting its dimensions and optionally resizing it.
ii <- data.frame(matrix(aperm(iris3, c(1,3,2)), ncol = 4,
                        dimnames = list(NULL, sub(" L.",".Length",
                                        sub(" W.",".Width", dni3[[2]])))), # To obtain names of variables from dni3 
    Species = gl(3, 50, labels = sub("S", "s", sub("V", "v", dni3[[3]]))))
all.equal(ii, iris) # Checks if new dataframe elements are equal to original iris dataframe. Output is 'TRUE'.
```
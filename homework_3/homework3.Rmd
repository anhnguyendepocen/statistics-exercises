---
title: "Homework 3 - Group E"
author: "Michela Venturini, Rabindra Khadka, Gabriele Sarti"
date: "April 22, 2019"
output:
  html_document:
    toc: true
    toc_depth: 2
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(42)
library(rstan);
```

# Lectures

## Exercise 1

**Compute the bootstrap-based confidence interval for the score dataset using the studentized method.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}

```

## Exercise 2

**Compute bootstrap-based confidence intervals for the score dataset using the boot package.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}

```

# Laboratory

## Exercise 1

**Use `nlm` to compute the variance for the estimator $ \hat w = (\log(\hat \gamma),\log(\hat \beta))$ and `optimHess` for the variance of $\hat \theta=(\hat \gamma, \hat \beta)$.**

```{r echo=TRUE, message=FALSE, warning=FALSE}

```

## Exercise 2

**The Wald confidence interval with level $1 - \alpha$ is defined as:**

$$\hat \gamma \pm z_{1−\alpha/2}j_P(\hat \gamma)^{−1/2}$$

**Compute the Wald confidence interval of level 0.95 and plot the results.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}

```

## Exercise 3

**Repeat the steps above —write the profile log-likelihood, plot it and find the deviance confidence intervals— considering this time γ as a nuisance parameter and β as the parameter of interest.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}

```

## Exercise 4

**Perform a test as above, but with:**

$$\begin{cases}
H_0 : \gamma = 1 \\
H_1 : \gamma = 5
\end{cases}
$$

## Exercise 5

**We found that the posterior mean is a weighted mean of the prior belief and the likelihood mean. Using some simple algebra, retrieve other two alternative expression for $\mu^{*}$, completing the following, and provide a nice interpretation.**

$$1)\;\;\mu^*=\bar y - \dots \\
2)\;\;\mu^* = \mu + \dots
$$

## Exercise 6

**In `sim` in the code above, you find the MCMC output which allows to approximate the posterior distribution of our parameter of interest with $S$ draws of θ. Please, produce an histogram for these random draws $\theta^{(1)},\dots,\theta^{(S)}, compute the empirical quantiles, and overlap the true posterior distribution.**

``` {r echo=TRUE,  message=FALSE, warning=FALSE}

``` 

## Exercise 7

**Launch the following line of R code:**

```{r echo=TRUE,  message=FALSE, warning=FALSE}
data<- list(N=10, y=rnorm(10,2,sqrt(2)), sigma =sqrt(2), mu = 7, tau = sqrt(2))
fit <- stan(file="normal.stan", data = data, chains = 4, iter=2000)
posterior <- as.array(fit)
```

**Use now the `bayesplot` package. Read the help and produce for this example, using the object posterior, the following plots:**

* **posterior intervals.**

* **posterior areas.**

* **marginal posterior distributions for the parameters.**

**Quickly comment.**

## Exercise 8

**Suppose you receive $n=15$ phone calls in a day, and you want to build a model to assess their average length. Your likelihood for each call length is $y_i \sim \text{Poisson}(\lambda)$. Now, you have to choose the prior $\pi(\lambda)$. Please, tell which of these priors is adequate to describe the problem, and provide a short motivation for each of them:**

**1. $\pi(\lambda) = \text{Beta}(4,2)$**

**2. $\pi(\lambda) = \text{Normal}(1,2)$**

**3. $\pi(\lambda) = \text{Gamma}(4,2)$**

**Now, compute your posterior as $\pi(\lambda|y) \propto L(\lambda;y)\pi(\lambda)$ for the selected prior. If your first choice was correct, you will be able to compute it analitically.**

## Exercise 9

**Go to this link: [rstan](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started), and follow the instructions to download and install the `rstan` library. Once you did it succesfully, open the file model called `biparametric.stan`, and replace the line:**

`target += cauchy_lpdf(sigma|0,2.5);`

**with the following one:**

`target += uniform_lpdf(sigma|0.1,10);`

**Which prior are you now assuming for your parameter $\sigma$? Reproduce the same plots as above and briefly comment.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}

```

## Exercise 10

**Reproduce the first plot above for the soccer goals, but this time by replacing Prior 1 with a $\text{Gamma}(2,4)$. Then, compute the final Bayes factor matrix ($\text{BF_matrix}$) with this new prior and the other ones unchanged, and comment. Is still Prior 2 favorable over all the others?**

## Exercise 11

**Let $y=(1,0,0,1,0,0,0,0,0,1,0,0,1,0)$ collect the results of tossing $n=14$ times an unfair coin, where 1 denotes _heads_ and 0 _tails_, and $p=Prob(y_i=1)$.**

* **Looking at the `Stan` code for the other models, write a short Stan Beta-Binomial model, where $p$ has a $\text{Beta}(a,b)$ prior with $a=3, b=3$.**

* **extract the posterior distribution with the function `extract()`**

* **produce some plots with the `bayesplot` package and comment.**

* **compute analitically the posterior distribution and compare it with the `Stan` distribution.**

```{r echo=TRUE,  message=FALSE, warning=FALSE}

```